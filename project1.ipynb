{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPokTHMj4Ec27JsW5fp+ZPy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fortune901/nubase-project/blob/main/project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddZVfIC1G1wK",
        "outputId": "a17aa871-1db4-4142-887d-d801dc7a8344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'nubase-project' already exists and is not an empty directory.\n",
            "[Errno 2] No such file or directory: 'nubase-project # va dans le dossier du depot'\n",
            "/content\n",
            "donnees_nubase.csv  nubase-project  sample_data\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/fortune901/nubase-project.git # cloner mon depot github\n",
        "%cd nubase-project # va dans le dossier du depot\n",
        "!ls #liste les fichiers pour verifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#importation des bibliothèques nécessaires\n",
        "\n",
        "import pandas as pd # pour lire et manipuler les données tabulaires (fichier.csv)\n",
        "from sklearn.model_selection import train_test_split # pour diviser les données en ensemble d'entrainement et de test\n",
        "from sklearn.preprocessing import StandardScaler # pour normaliser les données\n",
        "from tensorflow.keras.models import Sequential # ici c'est pour construire un modèle de reseau de neurone\n",
        "from tensorflow.keras.layers import Dense # ici c'est pour pouvoir ajouter des couches de neurones cachees\n",
        "\n",
        "#Extraction des donnees\n",
        "def extraire_donnees_nubase(fichier):\n",
        "  \"\"\"\n",
        "  Extrait les donnees nucleaires depuis le fichier nubase_4.mas20.\n",
        "  \"\"\"\n",
        "  donnees = []\n",
        "  with open(fichier, 'r', encoding='utf-8') as f:\n",
        "    for ligne in f:\n",
        "      if ligne.strip() == '' or ligne.startswith('#'): # cette ligne de code permet de sauter les lignes vides ou de commmentaire\n",
        "        continue\n",
        "      try:\n",
        "        #Lectures des champs depuis les positions fixes (selon la structure de nubase2020)\n",
        "        # attention : les indices peuvent varier selon les versions du fichier\n",
        "        Z = ligne[0:3].strip() # Numero atomique (proton)\n",
        "        N = ligne[4:8].strip() # Nombre de neutrons\n",
        "        A = ligne[9:13].strip() # Nombre de masse\n",
        "        element = ligne[14:17].strip() # Symbole de l'element\n",
        "        etat= ligne[18:19].strip() # état fonfamentale (g) ou isomere (m)\n",
        "        demi_vie = ligne[59:80].strip() # Demi-vie (au format texte, souvent log ou unité ex: '1.23 s')\n",
        "        deformation= ligne[90:100].strip() # Deformation nucleaire (si disponible)\n",
        "        shell_effect = ligne[100:110].strip() # Effet de coquille (ex: energie de liaison)\n",
        "        spin_orbite = ligne[110:120].strip() # Info sur le spin ou couplage (selon le format exact)\n",
        "        # Ajoutons les données sous formes de dictionnaire\n",
        "        donnees.append({'Z': Z,\n",
        "                       'N': N,\n",
        "                       'A': A,\n",
        "                       'Element': element,\n",
        "                       'Etat': etat,\n",
        "                       'Demi-vie': demi_vie,\n",
        "                       'Deformation': deformation,\n",
        "                       'Shell_effect': shell_effect,\n",
        "                       'Spin_orbite': spin_orbite})\n",
        "      except IndexError: # si une ligne est trop courte on l'ignore\n",
        "        continue\n",
        "    return donnees\n",
        "# Utilisation du script\n",
        "fichier = 'nubase_4.mas20'\n",
        "donnees = extraire_donnees_nubase(fichier)\n",
        "#affichage des 5 premiers lignes extraites\n",
        "for ligne in donnees[:5]:\n",
        "  print(ligne)\n",
        "# Utilisation du script\n",
        "fichier = 'nubase_4.mas20'\n",
        "donnees = extraire_donnees_nubase(fichier)\n",
        "#affichage des 5 premiers lignes extraites\n",
        "for ligne in donnees[:5]:\n",
        "  print(ligne)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "-Jzy5egMJ4c7",
        "outputId": "b90ec444-597d-4c75-93a2-09d0410e52bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'nubase_4.mas20'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1963650863>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Utilisation du script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mfichier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nubase_4.mas20'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdonnees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextraire_donnees_nubase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfichier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;31m#affichage des 5 premiers lignes extraites\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mligne\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdonnees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-1963650863>\u001b[0m in \u001b[0;36mextraire_donnees_nubase\u001b[0;34m(fichier)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \"\"\"\n\u001b[1;32m     14\u001b[0m   \u001b[0mdonnees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfichier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mligne\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mligne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mligne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# cette ligne de code permet de sauter les lignes vides ou de commmentaire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nubase_4.mas20'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "# Enregistrement dans un fichier CSV\n",
        "with open('donnees_nubase.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "  champs = ['Z', 'N','A','Element',  'Etat', 'Demi-vie', 'Deformation', 'Shell_effect', 'Spin_orbite']\n",
        "  writer = csv.DictWriter(csvfile, fieldnames=champs)\n",
        "  writer.writeheader()\n",
        "  writer.writerows(donnees)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "QRjKzkRMc--o",
        "outputId": "45bab61e-ce71-44c7-f40f-dff3e776b338"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'donnees' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1437807067>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdonnees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'donnees' is not defined"
          ]
        }
      ]
    }
  ]
}